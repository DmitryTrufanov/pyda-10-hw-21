{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм со столбцами: <дата> - <заголовок> - <ссылка>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очень часто сайты могут ограничивать частые запросы к себе,поэтому нужно задерживать исполнение\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://habr.com/ru/all'\n",
    "req = requests.get(URL)\n",
    "#req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем посты\n",
    "articles = soup.find_all('article', class_='post')\n",
    "#articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['oled', 'usb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []\n",
    "\n",
    "for article in articles:\n",
    "    posts_text = article.find_all('div', class_='post__text post__text-html post__text_v1') #выделение превью к статьям\n",
    "    for post_text in posts_text:\n",
    "        post_text_lower = post_text.text.lower()\n",
    "        #print(post_text_lower)\n",
    "        # ищем вхождение хотя бы одного желаемого хаба\n",
    "        if any([words in post_text_lower for words in KEYWORDS]):\n",
    "            #print(post_text_lower)\n",
    "        #else:\n",
    "            #print(\"нет\")\n",
    "            # пост нам интересен - делаем с ним все что захотим: можно отправит в телеграм уведомление, можно на почту и т.п.\n",
    "            title_element = article.find('a', class_='post__title_link')\n",
    "            a = title_element.attrs.get('href')\n",
    "            soup = BeautifulSoup(requests.get(a).text, 'html.parser')\n",
    "            time.sleep(0.3)\n",
    "            title_element2 = article.find('a', class_='post__title_link').text\n",
    "            date = article.find('span', class_='post__time').text\n",
    "            row = {'date': date, 'title': title_element2, 'ссылка': a}\n",
    "            list_1.append(row)\n",
    "            # так как пост уже нам подошел - дальше нет смысла проверять хабы\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>ссылка</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 23:47</td>\n",
       "      <td>Подключение OLED дисплея ssd1306 к STM32 (SPI+...</td>\n",
       "      <td>https://habr.com/ru/post/514382/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вчера в 20:58</td>\n",
       "      <td>Издеваемся над USB</td>\n",
       "      <td>https://habr.com/ru/post/514376/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                              title  \\\n",
       "0  вчера в 23:47  Подключение OLED дисплея ssd1306 к STM32 (SPI+...   \n",
       "1  вчера в 20:58                                 Издеваемся над USB   \n",
       "\n",
       "                             ссылка  \n",
       "0  https://habr.com/ru/post/514382/  \n",
       "1  https://habr.com/ru/post/514376/  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(list_1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "\n",
    "for article in articles:\n",
    "    posts_text = article.find_all('div', class_='post__text post__text-html post__text_v1') #выделение превью к статьям\n",
    "    for post_text in posts_text:\n",
    "        post_text_lower = post_text.text.lower()\n",
    "        #print(post_text_lower)\n",
    "        # ищем вхождение хотя бы одного желаемого хаба\n",
    "        if any([words in post_text_lower for words in KEYWORDS]):\n",
    "            #print(post_text_lower)\n",
    "        #else:\n",
    "            #print(\"нет\")\n",
    "            # пост нам интересен - делаем с ним все что захотим: можно отправит в телеграм уведомление, можно на почту и т.п.\n",
    "            title_element = article.find('a', class_='post__title_link')\n",
    "            a = title_element.attrs.get('href')\n",
    "            soup = BeautifulSoup(requests.get(a).text, 'html.parser')\n",
    "            time.sleep(0.3)\n",
    "            text = soup.find('div', class_='post__text post__text-html post__text_v1').text\n",
    "            title_element2 = article.find('a', class_='post__title_link').text\n",
    "            date = article.find('span', class_='post__time').text\n",
    "            row = {'date': date, 'title': title_element2, 'ссылка': a, 'text': text}\n",
    "            list_.append(row)\n",
    "            # так как пост уже нам подошел - дальше нет смысла проверять хабы\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>ссылка</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 23:47</td>\n",
       "      <td>Подключение OLED дисплея ssd1306 к STM32 (SPI+...</td>\n",
       "      <td>https://habr.com/ru/post/514382/</td>\n",
       "      <td>В данной статье будет описан процесс подключен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вчера в 20:58</td>\n",
       "      <td>Издеваемся над USB</td>\n",
       "      <td>https://habr.com/ru/post/514376/</td>\n",
       "      <td>\\r\\nВ очередной раз втыкая скоростную USB флеш...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                              title  \\\n",
       "0  вчера в 23:47  Подключение OLED дисплея ssd1306 к STM32 (SPI+...   \n",
       "1  вчера в 20:58                                 Издеваемся над USB   \n",
       "\n",
       "                             ссылка  \\\n",
       "0  https://habr.com/ru/post/514382/   \n",
       "1  https://habr.com/ru/post/514376/   \n",
       "\n",
       "                                                text  \n",
       "0  В данной статье будет описан процесс подключен...  \n",
       "1  \\r\\nВ очередной раз втыкая скоростную USB флеш...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list_)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\nВ очередной раз втыкая скоростную USB флешку в порт USB 3.0, я увидел надпись \"Это устройство может работать быстрее...\". Но подождите, я и так его воткнул в порт 3.0! Неужели контакт барахлит? И если так, то как флешка определяет, на какой скорости ей работать? Ведь современные ПК поддерживают целых три стандарта соединения — USB 1.1, 2.0 и 3.0. Можно ли «понизить» стандарт USB, насильно заставив устройство работать, к примеру, на USB 1.1? Не на все эти вопросы в сети удалось найти ответ, и я решил разобраться сам, по ходу столкнувшись с довольно неочевидными ситуациями.\\n\\nПонижаем USB 3.0 до 2.0Вы сейчас скажете — да что может быть проще, просто возьми USB 2.0 кабель — и будете совершенно правы. Если в кабеле или разъёме нет USB 3.0 контактов, у устройства не будет иного выхода, кроме как завестись на скорости USB 2.0:\\n\\n\\r\\nНо отключение каких конкретно проводков приведёт к переключению на USB 2.0? Что будет, если отключить только один, или замкнуть соседние? Интересно же выйти за рамки стандарта и поэкспериментировать!\\n\\r\\nДля экспериментов я спаял USB-«маму» и USB-«папу» проводками на макетной плате:\\n\\n\\r\\nНа фотографии не просто так один проводок находится в воздухе. Выяснилось, что соединение прекрасно работает даже без одного из проводников SS_TX дифф. пары! (для пары SS_RX такой фокус уже не работает)\\n\\r\\nБолее того, если отключить все USB 3.0 контакты, кроме SS_TX, девайс продолжает считать, что он подключен к USB 3.0 и вообще никак не обнаруживается в системе. Честно говоря, я был уверен, что соединение в этом случае переключится на 2.0 режим:\\n\\n здесь отключены SS_RX-, SS_RX+ и SS_TX+\\n\\r\\nИтого делаем вывод, что USB 3.0 устройство проверяет наличие SuperSpeed соединения по линии SS_TX, причём трансивер настолько устойчив к ошибкам, что ему плевать на обрыв одной из линий пары. Для гарантированного переключения устройства на USB 2.0 нужно рвать обе линии: SS_TX- и SS_TX+.\\n\\nПонижаем USB до 1.1\\r\\nUSB 2.0 всем хорош, да больно уж шустрый. Если вы когда-нибудь пытались заснифать его логическим анализатором, у вас либо очень крутой анализатор, либо вы нашли древний USB-хаб вроде такого:\\n\\n\\r\\nНесмотря на то, что интернет пестрит вопросами «как понизить USB 2.0 до 1.1», простого решения я нигде не увидел:\\n\\n\\r\\nДавайте глянем внимательнее! По стандарту USB, скорость работы согласуется на сигнальном уровне. Устройство поднимает вольтаж D- до 0.8в, а хост отвечает пилообразным сигналом:\\n\\n\\r\\nТо же самое видим на нашем «экспериментальном стенде» на осциллографе:\\n\\n\\r\\nТо есть, нужно сделать так, чтобы хост не увидел этого повышения напряжения. А значит — ставим диод в разрыв линии D- (Шоттки, чтобы минимизировать падение):\\n\\n\\r\\nИиии он успешно подавляет сигнал от устройства, не мешая обычной передаче данных:\\n\\n\\n\\n\\r\\nИ здесь я был уверен, что диод нарушит передачу данных по линии и ничего не заработает, но нет — я не смог найти ни одного устройства, которое не заработало через такой «переходник».\\n\\nСобираем «даунгрейдер»\\r\\nКак обобщение вышеописанных экспериментов, я сделал простенький пассивный переключатель USB режимов — 1.1/2.0/3.0\\n\\r\\nМоё стремление к простоте порой невозможно сдерживать. Захотелось всё реализовать на единственном трёхпозиционном переключателе, вот таком:\\n\\n\\n\\r\\nПервоначальная идея была — один ряд контактов переключает D- между:\\n\\n\\n«диод» (USB 1.1)\\n«пусто» (USB 3.0)\\n«D-» (USB 2.0)\\n\\r\\nА другой ряд контактов соединяет SS_TX- только в режиме USB 3.0:\\n\\n\\n«пусто» (USB 1.1)\\n«SS_TX-» (USB 3.0)\\n«пусто» (USB 2.0)\\n\\r\\nНо эту идею я отбросил из-за сомнений — вряд ли все USB 3.0 устройства смогут работать только на одной линии дифф. пары. Поэтому я переделал выключатель кусачками:\\n\\n\\r\\nТеперь средний контакт переключается между крайними, а в среднем положении выключатель замыкает две пары независимых контактов. Идеально! Осталось припаять и готово:\\n\\nTODO: развести печатную платку и сделать красиво\\n\\r\\nВсё, теперь можно быть уверенным, что флешка работает именно в 3.0 (2.0, 1.1) режиме, а иначе она просто не обнаружится в системе. В заключение, тестируем наш картридер в различных положениях выключателя.\\n\\r\\n«3.0»:\\n\\n«2.0»:\\nпочему-то скорость USB 1.1 не понравилась Crystal Disk Mark, и в результате теста он показал нули\\n\\nВопрос на засыпку\\r\\nВ USB 3.0 разъёме две пары контактов — USB 2.0 и USB 3.0, мы уже выяснили, что устройство (флешка, картридер) сначала лезет на контакты 3.0, а если не получается, переходит в 2.0 режим.\\n\\r\\nЧто, если к 3.0 контактам подключить одно устройство, а к 2.0 контактам — другое? Какое из устройств увидит компьютер? \\n\\n\\r\\nПопробуйте ответить в опросе ниже перед тем, как заглядывать под спойлер.\\n\\n\\nОтвет\\nДля этого эксперимента, спаяем вместе USB 3.0 SATA-адаптер и USB 2.0 флешку:\\n\\n\\n\\r\\nВставляем в комп и…\\n\\n\\r\\nУвиделось оба устройства! Да, на самом деле в каждом физическом USB 3.0 порту сразу два независимых порта. По крайней мере, у ПК на чипсетах Intel.\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text #действительно статья целиком, а не превью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = ['xxx@x.ru', 'yyy@y.com']\n",
    "URL3 = 'https://digibody.avast.com/v1/web/leaks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>Combolist of 1.4 Billion Credentials</td>\n",
       "      <td>The proliferation of stolen or leaked database...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>Collection #4 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>CD Projekt Red</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>Parapa</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>Collection #5 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>2019 Antipublic Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>CFire Mail</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-10-21</td>\n",
       "      <td>Adobe Systems</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>Collection #2 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>VK</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>Collection #1 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>iMesh</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>Combolist of 1.4 Billion Credentials</td>\n",
       "      <td>The proliferation of stolen or leaked database...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>Anti-Public Combolist</td>\n",
       "      <td>The proliferation of stolen or leaked database...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>Collection #4 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Canva</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>Dropbox</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>Rayli</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>2019 Antipublic Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>MyHeritage</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-10-21</td>\n",
       "      <td>Adobe Systems</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>Collection #2 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>Wishbone</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>Global Reach Technology</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-10-21</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-03-24</td>\n",
       "      <td>Youku</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AZCentral</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>Netlog</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>\"Cash Cloud\" Retail Combo List</td>\n",
       "      <td>At an unconfirmed date, this \"Cash Cloud\" Reta...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>iMesh</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                 title  \\\n",
       "0  2017-12-22  Combolist of 1.4 Billion Credentials   \n",
       "1  2019-02-06              Collection #4 Combo List   \n",
       "2  2017-01-31                        CD Projekt Red   \n",
       "3  2017-02-14                                Parapa   \n",
       "4  2017-03-08                      Sensitive Source   \n",
       "5  2019-02-06              Collection #5 Combo List   \n",
       "6  2019-02-06            2019 Antipublic Combo List   \n",
       "7  2017-02-14                            CFire Mail   \n",
       "8  2016-10-21                         Adobe Systems   \n",
       "9  2019-01-29              Collection #2 Combo List   \n",
       "10 2016-10-29                                    VK   \n",
       "11 2019-01-25              Collection #1 Combo List   \n",
       "12 2016-10-23                                 iMesh   \n",
       "0  2017-12-22  Combolist of 1.4 Billion Credentials   \n",
       "1  2017-10-18                 Anti-Public Combolist   \n",
       "2  2019-02-06              Collection #4 Combo List   \n",
       "3  2016-10-24                      Sensitive Source   \n",
       "4  2019-06-13                                 Canva   \n",
       "5  2016-10-24                               Dropbox   \n",
       "6  2017-03-01                                 Rayli   \n",
       "7  2020-02-13                      Sensitive Source   \n",
       "8  2019-02-06            2019 Antipublic Combo List   \n",
       "9  2018-04-10                      Sensitive Source   \n",
       "10 2018-12-21                      Sensitive Source   \n",
       "11 2017-11-04                            MyHeritage   \n",
       "12 2016-10-21                         Adobe Systems   \n",
       "13 2019-01-29              Collection #2 Combo List   \n",
       "14 2020-05-28                              Wishbone   \n",
       "15 2017-03-15               Global Reach Technology   \n",
       "16 2016-10-25                      Sensitive Source   \n",
       "17 2016-10-21                              LinkedIn   \n",
       "18 2017-03-24                                 Youku   \n",
       "19 2020-01-03                             AZCentral   \n",
       "20 2018-02-18                                Netlog   \n",
       "21 2020-06-25        \"Cash Cloud\" Retail Combo List   \n",
       "22 2020-01-09                      Sensitive Source   \n",
       "23 2016-10-23                                 iMesh   \n",
       "\n",
       "                                          description      email  \n",
       "0   The proliferation of stolen or leaked database...   xxx@x.ru  \n",
       "1   On January 7, 2019, an online user named Sanix...   xxx@x.ru  \n",
       "2   In March 2016, CDProjektRed.com.com's forum da...   xxx@x.ru  \n",
       "3   In July and August 2016, two criminals execute...   xxx@x.ru  \n",
       "4   This source has been marked as sensitive due t...   xxx@x.ru  \n",
       "5   On January 7, 2019, an online user named Sanix...   xxx@x.ru  \n",
       "6   On January 7, 2019, an online user named Sanix...   xxx@x.ru  \n",
       "7   In July and August of 2016, two criminals carr...   xxx@x.ru  \n",
       "8   In October of 2013, criminals penetrated Adobe...   xxx@x.ru  \n",
       "9   On January 7, 2019, an online user named Sanix...   xxx@x.ru  \n",
       "10  Popular Russian social networking platform VKo...   xxx@x.ru  \n",
       "11  On January 7, 2019, an online user named Sanix...   xxx@x.ru  \n",
       "12  In June 2016, a cache of over 51 million user ...   xxx@x.ru  \n",
       "0   The proliferation of stolen or leaked database...  yyy@y.com  \n",
       "1   The proliferation of stolen or leaked database...  yyy@y.com  \n",
       "2   On January 7, 2019, an online user named Sanix...  yyy@y.com  \n",
       "3   This source has been marked as sensitive due t...  yyy@y.com  \n",
       "4   In May 2019, graphic-design site Canva's datab...  yyy@y.com  \n",
       "5   Cloud storage company Dropbox suffered a major...  yyy@y.com  \n",
       "6   On an unconfirmed date, Chinese gossip site Ra...  yyy@y.com  \n",
       "7   This source has been marked as sensitive due t...  yyy@y.com  \n",
       "8   On January 7, 2019, an online user named Sanix...  yyy@y.com  \n",
       "9   This source has been marked as sensitive due t...  yyy@y.com  \n",
       "10  This source has been marked as sensitive due t...  yyy@y.com  \n",
       "11  In October 2017, a customer database belonging...  yyy@y.com  \n",
       "12  In October of 2013, criminals penetrated Adobe...  yyy@y.com  \n",
       "13  On January 7, 2019, an online user named Sanix...  yyy@y.com  \n",
       "14  In January 2020, the online poll website Wishb...  yyy@y.com  \n",
       "15  In 2016, Global Reach Technology's database wa...  yyy@y.com  \n",
       "16  This source has been marked as sensitive due t...  yyy@y.com  \n",
       "17  In 2012, online professional networking platfo...  yyy@y.com  \n",
       "18  Youku is a large Chinese video content company...  yyy@y.com  \n",
       "19  At an unconfirmed date, online Arizona newspap...  yyy@y.com  \n",
       "20  Netlog (formerly known as Facebox and Bingbox)...  yyy@y.com  \n",
       "21  At an unconfirmed date, this \"Cash Cloud\" Reta...  yyy@y.com  \n",
       "22  This source has been marked as sensitive due t...  yyy@y.com  \n",
       "23  In June 2016, a cache of over 51 million user ...  yyy@y.com  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = 'email'\n",
    "df4a = pd.DataFrame()\n",
    "\n",
    "for email_el in EMAIL:\n",
    "    params = {'email': email_el}\n",
    "    res3 = requests.post(URL3, json=params)\n",
    "\n",
    "    dict_all = json.loads(res3.text)\n",
    "    list_row = []\n",
    "    dict_value = dict_all['value']\n",
    "    for el in dict_value:\n",
    "        el = el['leak_info']\n",
    "        row = {'date': el['date'], 'title': el['title'], 'description': el['description'], email: email_el}\n",
    "        list_row.append(row) \n",
    "        #print(list_info)\n",
    "    df4 = pd.DataFrame(list_row)\n",
    "    df4[['date', 'title', 'description', 'email']]\n",
    "    df4['date'] = pd.to_datetime(df4['date'], unit='ms')\n",
    "    #print(df4)\n",
    "    df4a = df4a.append(df4)\n",
    "df4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: https://vk.com/dev/methods\n",
    ", вам поможет метод [wall.get](https://vk.com/dev/wall.get)```\n",
    "GROUP = 'netology'\n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "```\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРИМЕЧАНИЕ\n",
    "Домашнее задание сдается ссылкой на репозиторий [GitHub](https://github.com/).\n",
    "Не сможем проверить или помочь, если вы пришлете:\n",
    "- файлы;\n",
    "- архивы;\n",
    "- скриншоты кода.\n",
    "\n",
    "Все обсуждения и консультации по выполнению домашнего задания ведутся только на соответствующем канале в slack.\n",
    "\n",
    "##### Как правильно задавать вопросы аспирантам, преподавателям и коллегам?\n",
    "Прежде чем задать вопрос необходимо попробовать найти ответ самому в интернете. Навык самостоятельного поиска информации – один из важнейших, и каждый практикующий специалист любого уровня это делает каждый день.\n",
    "\n",
    "Любой вопрос должен быть сформулирован по алгоритму:  \n",
    "1) Что я делаю?  \n",
    "2) Какого результата я ожидаю?  \n",
    "3) Как фактический результат отличается от ожидаемого?  \n",
    "4) Что я уже попробовал сделать, чтобы исправить проблему?  \n",
    "\n",
    "По возможности, прикрепляйте к вопросу скриншоты, либо ссылки на код. Оставляйте только проблемный и воспроизводимый участок кода, все решение выкладывать не допускается.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
